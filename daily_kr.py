import yfinance as yf
import pandas as pd
import ta
import time
import os
from datetime import datetime, timedelta
from pandas_datareader import data as web
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization
import numpy as np
import matplotlib.pyplot as plt
import difflib
import xml.etree.ElementTree as ET
import requests
from datetime import datetime
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.font_manager as fm
import platform




# ------------------------
# ì„¤ì •
# ------------------------
# Pandas ì¶œë ¥ ì„¤ì • ë³€ê²½ (ëª¨ë“  ì»¬ëŸ¼ í‘œì‹œ)
pd.set_option('display.max_columns', None)
start_date = "2019-01-01"
end_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
API_KEY = 'VADVWXGUAJ1D7O7H9PKX'  # API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì…ë ¥í•˜ì„¸ìš”.

# âœ… í•œêµ­ ì£¼ì‹ í‹°ì»¤ ì„¤ì •
kr_tickers = {
    'ì‚¼ì„±ì „ì': '005930.KS',
    'SKí•˜ì´ë‹‰ìŠ¤': '000660.KS',
    'LGì—ë„ˆì§€ì†”ë£¨ì…˜': '373220.KS',
    'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤': '207940.KS',
    'í˜„ëŒ€ì°¨': '005380.KS',
    'ì¹´ì¹´ì˜¤': '035720.KS',
    'ê¸°ì•„': '000270.KS',
    'LGí™”í•™': '051910.KS',
    'NAVER': '035420.KS',
    'POSCOí™€ë”©ìŠ¤': '005490.KS'
}
ticker_to_name = {v: k for k, v in kr_tickers.items()}
start_date = "2019-01-01"
end_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')

OUTPUT_DIR = "data"
MERGED_FILE = os.path.join(OUTPUT_DIR, "kr_stock_macro_merged.csv")
PREDICTED_FILE = os.path.join(OUTPUT_DIR, "kr_predicted_with_scores.csv")
SIMULATION_FILE_SIMPLE_FORMATTED = os.path.join(OUTPUT_DIR, "kr_simulation_result_simple.csv")

FEATURE_COLUMNS = [
    # ğŸ”¹ OHLC ê°€ê²© ì •ë³´
    'Open', 'High', 'Low', 'Close',
    
    # ğŸ”¹ ê¸°ìˆ ì  ì§€í‘œ
    'ë³€í™”ìœ¨(%)', '5ì¼ì´í‰', '20ì¼ì´í‰', '60ì¼ì´í‰', 'RSI',
    'MACD', 'MACD_Signal', 'MACD_Histogram',
    'Bollinger_Bandwidth', 'Momentum_10', 'Cumulative_Return',
    
    # ğŸ”¹ ê±°ì‹œ ì§€í‘œ (ECOS ê¸°ë°˜)
    'í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬', 'ì½œê¸ˆë¦¬(ìµì¼ë¬¼)', 'ì˜ˆê¸ˆì€í–‰ ìˆ˜ì‹ ê¸ˆë¦¬', 'ì˜ˆê¸ˆì€í–‰ ëŒ€ì¶œê¸ˆë¦¬',
    'ê°€ê³„ì‹ ìš©', 'M2(ê´‘ì˜í†µí™”, í‰ì”)', 
    'ì‹¤ì—…ë¥ ', 'ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜', 'ë†ì‚°ë¬¼ ë° ì„ìœ ë¥˜ì œì™¸ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜'
]
# âœ… í†µê³„í‘œ ë° ì•„ì´í…œ ì½”ë“œ êµ¬ì¡° (ECOS)
stat_codes = {
    '722Y001': {'name': 'í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬', 'item_codes': [{'code': '0101000', 'cycle': 'Q'}]},
    '817Y002': {'name': 'ì½œê¸ˆë¦¬(ìµì¼ë¬¼)', 'item_codes': [{'code': '010101000', 'cycle': 'D'}]},
    '121Y002': {'name': 'ì˜ˆê¸ˆì€í–‰ ìˆ˜ì‹ ê¸ˆë¦¬', 'item_codes': [{'code': 'BEABAA2', 'cycle': 'M'}]},
    '121Y006': {'name': 'ì˜ˆê¸ˆì€í–‰ ëŒ€ì¶œê¸ˆë¦¬', 'item_codes': [{'code': 'BECBLA01', 'cycle': 'M'}]},
    '151Y001': {'name': 'ê°€ê³„ì‹ ìš©', 'item_codes': [{'code': '1000000', 'cycle': 'Q'}]},
    '101Y003': {'name': 'M2(ê´‘ì˜í†µí™”, í‰ì”)', 'item_codes': [{'code': 'BBHS00', 'cycle': 'M'}]},
    '901Y027': {'name': 'ì‹¤ì—…ë¥ ', 'item_codes': [{'code': 'I61BC', 'cycle': 'M'}]},
    '901Y009': {'name': 'ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜', 'item_codes': [{'code': '0', 'cycle': 'M'}]},
    '901Y010': {'name': 'ë†ì‚°ë¬¼ ë° ì„ìœ ë¥˜ì œì™¸ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜', 'item_codes': [{'code': '00', 'cycle': 'M'}]}
}

# ------------------------
# 1ë‹¨ê³„: ì£¼ê°€ + ê±°ì‹œì§€í‘œ ìˆ˜ì§‘
# ------------------------
# âœ… ECOS ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
def get_item_list(stat_code):
    url = f"https://ecos.bok.or.kr/api/StatisticItemList/{API_KEY}/xml/kr/1/1000/{stat_code}/"
    res = requests.get(url)
    root = ET.fromstring(res.content)

    item_list = []
    for row in root.findall(".//row"):
        item_code = row.findtext("ITEM_CODE")
        item_name = row.findtext("ITEM_NAME")
        cycle = row.findtext("CYCLE")
        if item_code and item_name and cycle:
            item_list.append(item_code)

    return item_list

def dmqa_check(stat_code, item_code):
    # âœ… ì‹¤ì œ ìœ íš¨í•œ ITEM_CODE ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    valid_codes = get_item_list(stat_code)
    if item_code not in valid_codes:
        # âœ… ìœ ì‚¬í•œ ì½”ë“œ ì°¾ê¸°
        suggestions = difflib.get_close_matches(item_code, valid_codes, n=3)
        print(f"\nâš ï¸ ì˜ëª»ëœ ITEM_CODE: '{item_code}'")
        if suggestions:
            print(f"ğŸ”„ ìˆ˜ì • ì œì•ˆ: {', '.join(suggestions)}")
        else:
            print("ğŸš« ìœ ì‚¬í•œ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    return True

# âœ… ECOS ë°ì´í„° ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
def get_ecos_data(stat_code, item_code, freq, name, start_date="201901", end_date="202505"):
    try:
        if not dmqa_check(stat_code, item_code):
            return pd.DataFrame()

        # âœ… ì£¼ê¸°ë³„ ë‚ ì§œ í¬ë§· ì§€ì •
        if freq == 'A':
            start_date, end_date = "2019", "2025"
        elif freq == 'M':
            start_date, end_date = "201901", "202504"
        elif freq == 'D':
            start_date, end_date = "20190101", "20250430"
        elif freq == 'Q':
            start_date, end_date = "2019Q1", "2024Q5"

        url = f"https://ecos.bok.or.kr/api/StatisticSearch/{API_KEY}/xml/kr/1/10000/{stat_code}/{freq}/{start_date}/{end_date}/{item_code}"
        res = requests.get(url)
        root = ET.fromstring(res.content)

        dates, values = [], []
        for row in root.findall(".//row"):
            time = row.findtext("TIME")
            value = row.findtext("DATA_VALUE")
            if time and value:
                if freq == 'M':
                    date = pd.to_datetime(time, format='%Y%m')
                elif freq == 'Q':
                    date = pd.to_datetime(time.replace("Q1", "-03-31").replace("Q2", "-06-30").replace("Q3", "-09-30").replace("Q4", "-12-31"))
                elif freq == 'A':
                    date = pd.to_datetime(time, format='%Y')
                elif freq == 'D':
                    date = pd.to_datetime(time, format='%Y%m%d')

                dates.append(date)
                values.append(float(value))

        if dates:
            df = pd.DataFrame(values, index=pd.to_datetime(dates), columns=[name])
            
            return df
        else:
            print(f"âš ï¸ {name} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

    except Exception as e:
        print(f"âŒ [ECOS ì˜¤ë¥˜] {name} ({stat_code}-{item_code}) â†’ {e}")
        return pd.DataFrame()

    dates, values = [], []
    for row in root.findall(".//row"):
        time = row.findtext("TIME")
        value = row.findtext("DATA_VALUE")
        if time and value:
            try:
                # âœ… ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                if freq == 'M':
                    date = pd.to_datetime(time, format='%Y%m')
                elif freq == 'Q':
                    date = pd.to_datetime(time.replace("Q1", "-03-31").replace("Q2", "-06-30").replace("Q3", "-09-30").replace("Q4", "-12-31"))
                elif freq == 'A':
                    date = pd.to_datetime(time, format='%Y')
                elif freq == 'D':
                    date = pd.to_datetime(time, format='%Y%m%d')

                # âœ… ì¤‘ë³µ ë°©ì§€
                if date not in dates:
                    dates.append(date)
                    values.append(float(value))

            except Exception as e:
                print(f"âš ï¸ ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {time}, {e}")
# âœ… ì¶”ê°€í•  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
def add_technical_indicators(df):
    # âœ… Log Return
    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))

    # âœ… MACD
    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = df['EMA_12'] - df['EMA_26']
    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']

    # âœ… Bollinger Bands
    df['Bollinger_Mid'] = df['Close'].rolling(window=20).mean()
    df['Bollinger_Upper'] = df['Bollinger_Mid'] + 2 * df['Close'].rolling(window=20).std()
    df['Bollinger_Lower'] = df['Bollinger_Mid'] - 2 * df['Close'].rolling(window=20).std()
    df['Bollinger_Bandwidth'] = (df['Bollinger_Upper'] - df['Bollinger_Lower']) / df['Bollinger_Mid'] * 100

    # âœ… Donchian Channel
    df['Donchian_High'] = df['Close'].rolling(window=20).max()
    df['Donchian_Low'] = df['Close'].rolling(window=20).min()

    # âœ… Momentum
    df['Momentum_10'] = df['Close'] - df['Close'].shift(10)

    # âœ… Cumulative Return
    df['Cumulative_Return'] = (df['Close'] / df['Close'].iloc[0] - 1) * 100

    return df

# âœ… ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ (ì›”ë³„ ë°ì´í„°)
def get_stock_data(name, ticker):
    stock = yf.Ticker(ticker)
    end_date_dynamic = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
    df = stock.history(start="2019-01-01", end=end_date_dynamic, interval='1d')  # ì¼ë³„ ë°ì´í„°

    if df.empty:
        print(f"âŒ {name} ({ticker}) ë°ì´í„° ì—†ìŒ")
        return pd.DataFrame()

    # âœ… ì¢…ëª©ëª… ì»¬ëŸ¼ ì¶”ê°€
    df['ì¢…ëª©ëª…'] = name
    df['Ticker'] = ticker 

    # âœ… ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    # ì´ë™í‰ê·  ê³„ì‚° ì´ˆë°˜ì—ëŠ” ìœˆë„ìš° í¬ê¸°ë§Œí¼ì˜ NaNì´ ë°œìƒí•©ë‹ˆë‹¤. (ê³„ì‚° íŠ¹ì„±)
    df["ë³€í™”ìœ¨(%)"] = df["Close"].pct_change() * 100
    df["5ì¼ì´í‰"] = df["Close"].rolling(window=5).mean()
    df["20ì¼ì´í‰"] = df["Close"].rolling(window=20).mean()
    df["60ì¼ì´í‰"] = df["Close"].rolling(window=60).mean()
    df["RSI"] = ta.momentum.RSIIndicator(close=df["Close"]).rsi()

    # âœ… ì‹œê°„ëŒ€ í†µì¼ (UTC -> Asia/Seoul) ë° ì›”ë³„ ì²«ì§¸ ë‚ ë¡œ ì¸ë±ìŠ¤ ì„¤ì •
    if df.index.tz is None:
        df.index = df.index.tz_localize('UTC').tz_convert('Asia/Seoul')
    elif df.index.tz.zone != 'Asia/Seoul':
        df.index = df.index.tz_convert('Asia/Seoul')
    # ì£¼ì‹ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ ì›”ì˜ ì²«ì§¸ ë‚ ë¡œ í†µì¼
    df = df.ffill().bfill()
    
    df = add_technical_indicators(df)

    df.reset_index(inplace=True)
    return df





def update_stock_and_macro_data():
    print("[1ë‹¨ê³„] í•œêµ­ ì£¼ê°€ + ê±°ì‹œì§€í‘œ ìˆ˜ì§‘ ë° ë³‘í•© ì‹œì‘")

    # âœ… ECOS ì§€í‘œ ìˆ˜ì§‘
    ecos_df_list = []
    for code, details in stat_codes.items():
        for item in details["item_codes"]:
            df = get_ecos_data(code, item["code"], item["cycle"], details["name"])
            print(f"ğŸ“¦ {details['name']} ({code}-{item['code']}) â†’", "âœ… ì„±ê³µ" if not df.empty else "âŒ ì‹¤íŒ¨")
            if df is not None and not df.empty:
                ecos_df_list.append(df)
    # âœ… í•˜ë‚˜ë„ ëª» ê°€ì ¸ì˜¨ ê²½ìš° ì—ëŸ¬ ë°©ì§€
    if not ecos_df_list:
        print("âŒ ëª¨ë“  ECOS ì§€í‘œ ìˆ˜ì§‘ ì‹¤íŒ¨. API í‚¤ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None
    
    for i in range(len(ecos_df_list)):
        df = ecos_df_list[i]
        df = df[~df.index.duplicated()]                  # ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±°
        df = df.sort_index()                             # ì¸ë±ìŠ¤ ì •ë ¬
        
        ecos_df_list[i] = df

    # ğŸ”¹ ë³‘í•©
    macro_df = pd.concat(ecos_df_list, axis=1)
    macro_df = macro_df[~macro_df.index.duplicated()]  # ë³‘í•© í›„ ì¤‘ë³µ ì œê±°
    macro_df = macro_df.sort_index()       

    # âœ… í•œêµ­ ì£¼ê°€ ìˆ˜ì§‘ + ê¸°ìˆ ì  ì§€í‘œ
    stock_data_list = [get_stock_data(name, ticker) for name, ticker in kr_tickers.items()]
    stock_data_list = [df for df in stock_data_list if not df.empty]

    if not stock_data_list:
        print("âŒ ì£¼ê°€ ìˆ˜ì§‘ ì‹¤íŒ¨")
        return None

    all_stock_data = pd.concat(stock_data_list, ignore_index=True)

    # âœ… ë‚ ì§œ ë³‘í•©: ì£¼ì‹ì€ 'Date', ê±°ì‹œì§€í‘œëŠ” index â†’ reset í›„ ë³‘í•©
    macro_df = macro_df.reset_index()

    # âœ… ì—¬ê¸°ì—ì„œ íƒ€ì„ì¡´ ì œê±° ì¶”ê°€
    all_stock_data["Date"] = pd.to_datetime(all_stock_data["Date"]).dt.tz_localize(None)
    macro_df["index"] = pd.to_datetime(macro_df["index"]).dt.tz_localize(None)
    merged_df = pd.merge(all_stock_data, macro_df, left_on="Date", right_on="index", how="left")
    merged_df.drop(columns=["index"], inplace=True)

    # âœ… ê²°ì¸¡ì¹˜ ë³´ê°„ + ì €ì¥
    merged_df.ffill(inplace=True)
    merged_df.bfill(inplace=True)
    merged_df["UpdatedAt"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    merged_df.to_csv(MERGED_FILE, index=False, encoding="utf-8-sig")

    print(f"[1ë‹¨ê³„] ì €ì¥ ì™„ë£Œ â†’ {MERGED_FILE}")
    return merged_df

# ------------------------
# 2ë‹¨ê³„: AI ëª¨ë¸ ì˜ˆì¸¡
# ------------------------
def predict_ai_scores(df):
    print("[2ë‹¨ê³„] AI ì˜ˆì¸¡ ì‹œì‘")

    df["Date"] = pd.to_datetime(df["Date"]).dt.tz_localize(None)
    df = df.loc[:, ~df.columns.duplicated()]

    # ìˆ˜ìµë¥  ë° íƒ€ê²Ÿ ìƒì„±
    df["Target_1D"] = df.groupby("Ticker")["Close"].shift(-1)
    df["Target_20D"] = df.groupby("Ticker")["Close"].shift(-20)
    df["Return_1D"] = (df["Target_1D"] - df["Close"]) / df["Close"]
    df["Return_20D"] = (df["Target_20D"] - df["Close"]) / df["Close"]
    df["Return"] = df.groupby("Ticker")["Close"].pct_change()
    df = df.ffill().bfill()

    # í›ˆë ¨ ë°ì´í„° ë¶„ë¦¬
    train_df = df[df["Date"] <= pd.to_datetime("2024-12-31")].copy()
    X_train = train_df[FEATURE_COLUMNS].fillna(0)
    y_train_1d = train_df["Return_1D"]
    y_train_20d = train_df["Return_20D"]

    # Gradient Boosting ëª¨ë¸ í•™ìŠµ
    gb_1d = GradientBoostingRegressor()
    gb_1d.fit(X_train, y_train_1d)

    gb_20d = GradientBoostingRegressor()
    gb_20d.fit(X_train, y_train_20d)

    # âœ… LSTM: ì‹œí€€ìŠ¤ ìƒì„±
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Input
    from tensorflow.keras.callbacks import EarlyStopping

    SEQUENCE_LENGTH = 10
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X_train)
    scaled_df = pd.DataFrame(X_scaled)

    X_lstm_train, y_lstm_train = [], []
    for i in range(SEQUENCE_LENGTH, len(scaled_df)):
        X_lstm_train.append(scaled_df.iloc[i - SEQUENCE_LENGTH:i].values)
        y_lstm_train.append(y_train_1d.iloc[i])

    X_lstm_train = np.array(X_lstm_train)
    y_lstm_train = np.array(y_lstm_train)

    # âœ… LSTM ëª¨ë¸ ì •ì˜ (seed ê³ ì • ì—†ìŒ)
    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    lstm_model = Sequential()
    lstm_model.add(Input(shape=(SEQUENCE_LENGTH, X_scaled.shape[1])))
    lstm_model.add(LSTM(128, return_sequences=False))
    lstm_model.add(BatchNormalization())
    lstm_model.add(Dropout(0.2))
    lstm_model.add(Dense(64, activation='relu'))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(Dense(32, activation='relu'))
    lstm_model.add(Dense(1))
    lstm_model.compile(optimizer='adam', loss='mse')
    lstm_model.fit(
        X_lstm_train,
        y_lstm_train,
        epochs=30,
        batch_size=16,
        validation_split=0.1,
        callbacks=[early_stop],
        verbose=1
    )

    # âœ… ì˜ˆì¸¡ ì‹œì‘
    test_dates = df[df["Date"] >= pd.to_datetime("2025-05-01")]["Date"].drop_duplicates().sort_values()
    all_preds = []

    for current_date in test_dates:
        test_df = df[df["Date"] == current_date].copy()
        if test_df.empty:
            continue

        test_df[FEATURE_COLUMNS] = test_df[FEATURE_COLUMNS].fillna(method='ffill').fillna(method='bfill').fillna(0)
        if test_df[FEATURE_COLUMNS].isnull().values.any():
            print(f"âš ï¸ {current_date.date()} â†’ ì—¬ì „íˆ NaN ìˆìŒ, ì˜ˆì¸¡ ìŠ¤í‚µ")
            continue

        # âœ… GB ì˜ˆì¸¡
        test_df["Predicted_Return_GB_1D"] = gb_1d.predict(test_df[FEATURE_COLUMNS]) * 4
        test_df["Predicted_Return_GB_20D"] = gb_20d.predict(test_df[FEATURE_COLUMNS])

        # âœ… LSTM ì˜ˆì¸¡ (ì¢…ëª©ë³„ ê³¼ê±° 10ì¼ ê¸°ì¤€)
        lstm_preds = []
        valid_rows = []

        for _, row in test_df.iterrows():
            ticker = row["Ticker"]
            date = row["Date"]
            past_window = df[(df["Ticker"] == ticker) & (df["Date"] < date)].sort_values("Date").tail(SEQUENCE_LENGTH)

            if len(past_window) < SEQUENCE_LENGTH:
                continue

            past_feats = past_window[FEATURE_COLUMNS].fillna(0)
            scaled_feats = scaler.transform(past_feats)
            input_seq = np.expand_dims(scaled_feats, axis=0)
            pred = lstm_model.predict(input_seq, verbose=0)[0][0]
            lstm_preds.append(pred * 30)
            valid_rows.append(row)

        if not valid_rows:
            continue

        test_df = pd.DataFrame(valid_rows)
        test_df["Predicted_Return_LSTM"] = lstm_preds

        all_preds.append(test_df)
        print(f"âœ… {current_date.date()} ì˜ˆì¸¡ ì™„ë£Œ - {len(test_df)}ì¢…ëª©")

    if not all_preds:
        print("âŒ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ. ì‹œë®¬ë ˆì´ì…˜ ë¶ˆê°€")
        return pd.DataFrame()

    result_df = pd.concat(all_preds, ignore_index=True)

    # âœ… ì˜ˆì¸¡ ì¢…ê°€ ê³„ì‚°
    result_df["ì˜ˆì¸¡ì¢…ê°€_GB_1D"] = result_df["Close"] * (1 + result_df["Predicted_Return_GB_1D"])
    result_df["ì˜ˆì¸¡ì¢…ê°€_GB_20D"] = result_df["Close"] * (1 + result_df["Predicted_Return_GB_20D"])
    result_df["ì˜ˆì¸¡ì¢…ê°€_LSTM"] = result_df["Close"] * (1 + result_df["Predicted_Return_LSTM"])

    result_df.to_csv(PREDICTED_FILE, index=False)
    print(f"[2ë‹¨ê³„] ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {PREDICTED_FILE}")
    return result_df



# ------------------------
SIMULATION_FILE_SIMPLE_FORMATTED = "data/kr_simulation_result_simple.csv"

def simulate_combined_trading_simple_formatted(df):
    print("[3ë‹¨ê³„] í†µí•© ëª¨ì˜íˆ¬ì ì‹œì‘ (ëˆ„ì  ë³´ìœ  + ì¡°ê±´ë¶€ ë¶€ë¶„ë§¤ë„)")

    initial_capital = 10000000
    portfolios = {
        "GB_1D": {"capital": initial_capital, "holding": {}},
        "GB_20D": {"capital": initial_capital, "holding": {}},
        "Dense-LSTM": {"capital": initial_capital, "holding": {}},
    }
    history = []
    TRADE_AMOUNT = 2000000

    df_sorted = df.sort_values(by=["Date", "Ticker"]).copy()
    df_sorted = df_sorted.fillna(method='ffill').fillna(method='bfill')
    df_sorted["Date"] = pd.to_datetime(df_sorted["Date"]).dt.tz_localize(None)
    df_sorted = df_sorted[
    (df_sorted["Date"] >= pd.to_datetime("2025-05-01")) &
    (df_sorted["Date"] <= pd.to_datetime(datetime.now().strftime("%Y-%m-%d")))
]

    if df_sorted.empty:
        print("  - ì‹œë®¬ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    print(f"  - {df_sorted['Date'].min().date()} ë¶€í„° ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘...")

    for date, date_df in df_sorted.groupby("Date"):
        for model, score_col in zip(
            portfolios.keys(),
            ["Predicted_Return_GB_1D", "Predicted_Return_GB_20D", "Predicted_Return_LSTM"]
        ):
            portfolio = portfolios[model]
            current_holdings = list(portfolio["holding"].keys())

            # 1. ë§¤ë„ íŒë‹¨
            for ticker in current_holdings:
                holding_info = portfolio["holding"][ticker]
                holding_stock_data = date_df[date_df["Ticker"] == ticker]

                if not holding_stock_data.empty:
                    current_price = holding_stock_data.iloc[0]["Close"]
                    holding_score = holding_stock_data.iloc[0][score_col]
                    holding_value = holding_info["shares"] * current_price

                    if holding_score <= -0.02:
                        shares_to_sell_value = min(TRADE_AMOUNT, holding_value)
                        shares_to_sell = int(shares_to_sell_value // current_price)

                        if shares_to_sell == 0 and holding_value > 0:
                            shares_to_sell = 1
                        shares_to_sell = min(shares_to_sell, holding_info["shares"])

                        if shares_to_sell > 0:
                            sell_price = current_price
                            sell_amount = shares_to_sell * sell_price * 0.999
                            portfolio["capital"] += sell_amount
                            portfolio["holding"][ticker]["shares"] -= shares_to_sell

                            buy_price = holding_info["buy_price"]
                            profit = (sell_price * 0.999 - buy_price) * shares_to_sell
                            profit_str = f"{profit:+.2f}ë‹¬ëŸ¬"

                            total_asset_after_sell = portfolio["capital"] + sum(
                                h["shares"] * current_price for h in portfolio["holding"].values()
                            )

                            history.append({
                                "ë‚ ì§œ": date,
                                "ëª¨ë¸": model,
                                "ì¢…ëª©ëª…": ticker_to_name.get(ticker, ticker),
                                "ì˜ˆì¸¡ ìˆ˜ìµë¥ ": holding_score * 10000,
                                "í˜„ì¬ê°€": sell_price,
                                "ë§¤ìˆ˜(ë§¤ë„)": f"SELL ({shares_to_sell}ì£¼)",
                                "ì”ì—¬ í˜„ê¸ˆ": portfolio["capital"],
                                "ì´ ìì‚°": total_asset_after_sell
                            })

                            if portfolio["holding"][ticker]["shares"] <= 0:
                                del portfolio["holding"][ticker]

            # 2. ë§¤ìˆ˜ íŒë‹¨ (ì˜ˆì¸¡ ìˆ˜ìµë¥  > 1%ì¸ ìƒìœ„ 4ê°œ ì¢…ëª©)
            top_candidates = date_df[date_df[score_col] > 0.01].sort_values(by=score_col, ascending=False).head(2)

            for _, row in top_candidates.iterrows():
                ticker = row["Ticker"]
                score = row[score_col]

                if portfolio["capital"] >= TRADE_AMOUNT:
                    buy_price = row["Close"]
                    buy_value_to_spend = min(TRADE_AMOUNT, portfolio["capital"] * 0.99)
                    shares = int(buy_value_to_spend // (buy_price * 1.001))

                    if shares > 0:
                        cost = shares * buy_price * 1.001
                        portfolio["capital"] -= cost

                        if ticker in portfolio["holding"]:
                            portfolio["holding"][ticker]["shares"] += shares
                        else:
                            portfolio["holding"][ticker] = {
                                "shares": shares,
                                "buy_price": buy_price
                            }

                        total_asset_after_buy = portfolio["capital"] + sum(
                            h["shares"] * buy_price for h in portfolio["holding"].values()
                        )

                        history.append({
                            "ë‚ ì§œ": date,
                            "ëª¨ë¸": model,
                            "ì¢…ëª©ëª…": ticker_to_name.get(ticker, ticker),
                            "í‹°ì»¤": ticker,
                            "ì˜ˆì¸¡ ìˆ˜ìµë¥ ": score * 10000,
                            "í˜„ì¬ê°€": buy_price,
                            "ë§¤ìˆ˜(ë§¤ë„)": f"BUY ({shares}ì£¼)",
                            "ì”ì—¬ í˜„ê¸ˆ": portfolio["capital"],
                            "ì´ ìì‚°": total_asset_after_buy
                        })

    result_df = pd.DataFrame(history)
    if not result_df.empty:
        # âœ… ì˜ˆì¸¡ ì¢…ê°€ ê³„ì‚° (ì˜ˆì¸¡ ìˆ˜ìµë¥ ì´ x10000 ë‹¨ìœ„)
        result_df["ì˜ˆì¸¡ì¢…ê°€"] = result_df["í˜„ì¬ê°€"] * (1 + result_df["ì˜ˆì¸¡ ìˆ˜ìµë¥ "] / 10000)
    
        result_df = result_df[["ë‚ ì§œ", "ëª¨ë¸", "ì¢…ëª©ëª…", "í‹°ì»¤", "ì˜ˆì¸¡ ìˆ˜ìµë¥ ", "í˜„ì¬ê°€", "ì˜ˆì¸¡ì¢…ê°€", "ë§¤ìˆ˜(ë§¤ë„)", "ì”ì—¬ í˜„ê¸ˆ", "ì´ ìì‚°"]]
        os.makedirs("data", exist_ok=True)
        result_df.to_csv(SIMULATION_FILE_SIMPLE_FORMATTED, index=False)
        print(f"[3ë‹¨ê³„] ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {SIMULATION_FILE_SIMPLE_FORMATTED}")
    else:
        print("[3ë‹¨ê³„] ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì—†ìŒ")

    final_assets = {}
    for model, port in portfolios.items():
        holding_summary = {}
        total_holding_value = 0
        for ticker, info in port["holding"].items():
            latest_price_row = df_sorted[df_sorted["Ticker"] == ticker].sort_values(by="Date", ascending=False).head(1)

            if not latest_price_row.empty:
                current_price = latest_price_row.iloc[0]["Close"]
                shares = info["shares"]
                holding_value = shares * current_price
                holding_summary[ticker] = {
                    "ë³´ìœ  ìˆ˜ëŸ‰": shares,
                    "í˜„ì¬ê°€": round(current_price, 2),
                    "í‰ê°€ ê¸ˆì•¡": round(holding_value, 2)
                }
                total_holding_value += holding_value

        total_asset = total_holding_value + port["capital"]
        final_assets[model] = {
            "í˜„ê¸ˆ ì”ì•¡": round(port["capital"], 2),
            "ì´ ìì‚°": round(total_asset, 2),
            "ë³´ìœ  ì¢…ëª© ìˆ˜": len(port["holding"]),
            "ë³´ìœ  ì¢…ëª©": holding_summary
        }

    return result_df, final_assets

# 4ë‹¨ê³„: ì‹œê°í™” (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¡œëŠ” ì‹œê°í™”ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)
# ------------------------
def visualize_trades_simple(df, sim_df_simple):
    print("[4ë‹¨ê³„] ì‹œê°í™” ì‹œì‘")
    os.makedirs("charts", exist_ok=True)

    # âœ… í•œê¸€ ê¹¨ì§ ë°©ì§€ìš© í°íŠ¸ ì„¤ì •
    if platform.system() == 'Windows':
        font_path = "C:/Windows/Fonts/malgun.ttf"
    else:
        font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
    
    font_name = fm.FontProperties(fname=font_path).get_name()
    plt.rcParams["font.family"] = font_name
    plt.rcParams["axes.unicode_minus"] = False

    df["Date"] = pd.to_datetime(df["Date"]).dt.tz_localize(None)
    sim_df_simple["ë‚ ì§œ"] = pd.to_datetime(sim_df_simple["ë‚ ì§œ"]).dt.tz_localize(None)

    # âœ… ì‚¼ì„±ì „ìë§Œ í•„í„°ë§
    target_stock = "ì‚¼ì„±ì „ì"
    ticker = df[df["ì¢…ëª©ëª…"] == target_stock]["Ticker"].unique()[0]
    stock_df = df[df["Ticker"] == ticker].sort_values(by="Date")

    fig, ax = plt.subplots(figsize=(14, 6))
    ax.plot(stock_df["Date"], stock_df["Close"], label="ì¢…ê°€", linewidth=2, alpha=0.7)

    for model in sim_df_simple["ëª¨ë¸"].unique():
        trades = sim_df_simple[(sim_df_simple["í‹°ì»¤"] == ticker) & (sim_df_simple["ëª¨ë¸"] == model)].copy()

        if trades.empty:
            continue

        trades = pd.merge(
            trades,
            stock_df[["Date", "Close"]].rename(columns={"Close": "Actual_Close"}),
            left_on="ë‚ ì§œ",
            right_on="Date",
            how="left"
        )

        # âœ… ë§¤ìˆ˜/ë§¤ë„ ì‹œê°í™”
        buys = trades[trades["ë§¤ìˆ˜(ë§¤ë„)"].str.contains("BUY", na=False)]
        sells = trades[trades["ë§¤ìˆ˜(ë§¤ë„)"].str.contains("SELL", na=False)]

        ax.scatter(buys["ë‚ ì§œ"], buys["Actual_Close"], label=f"{model} ë§¤ìˆ˜", marker="^", color="green", zorder=5)
        ax.scatter(sells["ë‚ ì§œ"], sells["Actual_Close"], label=f"{model} ë§¤ë„", marker="v", color="red", zorder=5)

        # âœ… MAE ê³„ì‚°
        if "Predicted_Return_LSTM" in trades.columns and "Actual_Close" in trades.columns:
            trades["ì˜ˆì¸¡_ì¢…ê°€"] = trades["Actual_Close"] * (1 + trades["Predicted_Return_LSTM"])
            mae = mean_absolute_error(trades["Actual_Close"], trades["ì˜ˆì¸¡_ì¢…ê°€"])
            ax.plot(trades["ë‚ ì§œ"], trades["ì˜ˆì¸¡_ì¢…ê°€"], label="Dense-LSTM ì˜ˆì¸¡ ì¢…ê°€", linestyle="--", alpha=0.7)
        else:
            mae = np.nan

        # âœ… íƒ€ì´í‹€ì— MAE ì¶”ê°€
        ax.set_title(f"ì‚¼ì„±ì „ì - Dense-LSTM ì‹œë®¬ë ˆì´ì…˜ (MAE: {mae:.2f})")

    ax.set_xlabel("ë‚ ì§œ")
    ax.set_ylabel("ì£¼ê°€ (ì›)")
    ax.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.rcParams["font.family"] = font_name
    plt.rcParams["axes.unicode_minus"] = False

    # âœ… ì €ì¥
    save_path = f"charts/SAMSUNG_trades_simple_Dense-LSTM.png"
    plt.savefig(save_path)
    plt.close()
    print(f"[ì™„ë£Œ] â†’ {save_path}")


# ------------------------
# ì‹¤í–‰
# ------------------------
if __name__ == "__main__":
    merged_df = update_stock_and_macro_data()
    if merged_df is not None:
        merged_df["Date"] = pd.to_datetime(merged_df["Date"])
        latest_date = merged_df["Date"].max().date()
        print(f"ğŸ“… ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ ê°€ì¥ ê²°ì • ë‚ ì§œ: {latest_date}")

        predicted_df = predict_ai_scores(merged_df.copy())

        if not predicted_df.empty:
            simulation_results_simple, final_assets = simulate_combined_trading_simple_formatted(predicted_df.copy())

            if not simulation_results_simple.empty:
                # ê°„ë‹¨í•œ ì‹œë®¬ë¦¬ì–¸ ê²°ê³¼ë¡œëŠ” ë³´ê°œí™”ëŠ” Ã¬ \xec96bìŒ
                # ê±°ë˜ ì‹œì ë§Œ í‘œì‹œí•˜ëŠ” ì‹œê°„ê°„í™” í•¨ìˆ˜ ì‚¬ìš©
                visualize_trades_simple(merged_df.copy(), simulation_results_simple.copy())

            print("\nğŸ“Š [ì˜ˆì¸¡ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° - ë§ˆì§€ë§‰ 20í–‰]")
            print(predicted_df.tail(20))

            print("\nğŸ“ˆ [ì‹œë®¬ë¦¬ì–¸ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° - ì²«ë²ˆì§¸ 2í–‰]")
            print(simulation_results_simple.to_string(index=False))

            print("\nğŸ’¼ [ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤ ìì‚¬í˜„í™©]")
            if not simulation_results_simple.empty:
                for model, info in final_assets.items():
                    print(f"\nğŸ“Œ ëª¨ë¸: {model}")
                    print(f"  - ì´ ìì‚°: {info['ì´ ìì‚°']}")
                    print(f"  - í˜„ê¸ˆ ì”ì•¡: {info['í˜„ê¸ˆ ì”ì•¡']}")
                    print(f"  - ë³´ìœ  ì¢…ëª© ìˆ˜: {info['ë³´ìœ  ì¢…ëª© ìˆ˜']}")

                    if info["ë³´ìœ  ì¢…ëª©"]:
                        print("  - ë³´ìœ  ì¢…ëª©:")
                        for ticker, details in info["ë³´ìœ  ì¢…ëª©"].items():
                            stock_name = ticker_to_name.get(ticker, ticker)
                            print(f"     â–¸ {stock_name}: ìˆ˜ëŸ‰={details['ë³´ìœ  ìˆ˜ëŸ‰']}ì£¼, í˜„ì¬ê°€=${details['í˜„ì¬ê°€']}, í‰ê°€ê¸ˆì•¡=${details['í‰ê°€ ê¸ˆì•¡']}")
                    else:
                        print("  - ë³´ìœ  ì¢…ëª© ì—†ìŒ")
        else:
            print("ì‹œë®¬ë¦¬ì–¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
